{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AvP4EManrl8w"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "      predictions = []\n",
        "      for x in X:\n",
        "        distances = self.compute_distance(x)\n",
        "        k_indices = np.argsort(distances)[:self.k]\n",
        "        k_nearest_labels = self.y_train[k_indices]\n",
        "        most_common = Counter(k_nearest_labels).most_common(1)\n",
        "        predictions.append(most_common[0][0])\n",
        "      return np.array(predictions)\n",
        "\n",
        "    def compute_distance(self, x):\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((self.X_train - x)**2, axis=1))\n",
        "        elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(self.X_train - x), axis=1)\n",
        "        else:\n",
        "            raise ValueError(\"Unsupported distance metric\")\n",
        "\n",
        "    def probabilities(self, X):\n",
        "        probas = []\n",
        "        for x in X:\n",
        "            distances = self.compute_distance(x)\n",
        "            k_indices = np.argsort(distances)[:self.k]\n",
        "            k_nearest_labels = self.y_train[k_indices]\n",
        "            class_counts = Counter(k_nearest_labels)\n",
        "            total = sum(class_counts.values())\n",
        "            proba = {class_label: count / total for class_label, count in class_counts.items()}\n",
        "            probas.append([proba.get(0, 0), proba.get(1, 0)])  # Assuming binary classification (0 and 1)\n",
        "        return np.array(probas)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def preprocess_data(train_path, test_path):\n",
        "    # Load the data\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Combine train and test for preprocessing\n",
        "    all_data = pd.concat([train_data, test_data], axis=0, sort=False)\n",
        "\n",
        "    # Handle missing values\n",
        "    numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "    categorical_features = ['Geography', 'Gender']\n",
        "\n",
        "    for feature in numeric_features:\n",
        "        median_value = all_data[feature].median()\n",
        "        all_data[feature].fillna(median_value, inplace=True)\n",
        "\n",
        "    # Handle categorical variables\n",
        "    all_data = pd.get_dummies(all_data, columns=categorical_features, drop_first=True)\n",
        "\n",
        "    # Transforming numeric featues to have mean 0 and sd 1\n",
        "    for feature in numeric_features:\n",
        "        mean_value = all_data[feature].mean()\n",
        "        std_value = all_data[feature].std()\n",
        "        all_data[feature] = (all_data[feature] - mean_value) / std_value\n",
        "\n",
        "    # Split data back into train and test just like it was split before\n",
        "    train_preprocessed = all_data[:len(train_data)]\n",
        "    test_preprocessed = all_data[len(train_data):]\n",
        "\n",
        "    # Prepare features and target for train data\n",
        "    X_train = train_preprocessed.drop(['Exited', 'id', 'CustomerId', 'Surname'], axis=1)\n",
        "    y_train = train_preprocessed['Exited'] #target column\n",
        "\n",
        "    # Prepare features for test data\n",
        "    X_test = test_preprocessed.drop(['id', 'CustomerId', 'Surname'], axis=1)\n",
        "    if 'Exited' in X_test.columns:\n",
        "        X_test = X_test.drop('Exited', axis=1)\n",
        "\n",
        "    return X_train.values, y_train.values, X_test.values"
      ],
      "metadata": {
        "id": "lP55IjUuzInr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "k9FO6G4yrl8x"
      },
      "outputs": [],
      "source": [
        "def k_fold_split(X, y, n_splits=5):\n",
        "    \"\"\"\n",
        "    Custom implementation of k-fold split (not stratified).\n",
        "    Splits data into `n_splits` folds for cross-validation.\n",
        "    \"\"\"\n",
        "    indices = np.arange(len(X))\n",
        "    np.random.shuffle(indices)\n",
        "    fold_sizes = np.full(n_splits, len(X) // n_splits, dtype=int)\n",
        "    fold_sizes[:len(X) % n_splits] += 1  # Distribute remainder to some folds\n",
        "\n",
        "    current = 0\n",
        "    folds = []\n",
        "    for fold_size in fold_sizes:\n",
        "        start, stop = current, current + fold_size\n",
        "        folds.append(indices[start:stop])\n",
        "        current = stop\n",
        "    return folds\n",
        "\n",
        "def custom_roc_auc_score(y_true, y_pred_proba):\n",
        "    # Sort by predicted probabilities (in descending order)\n",
        "    desc_order = np.argsort(-y_pred_proba)\n",
        "    y_true = y_true[desc_order]\n",
        "    y_pred_proba = y_pred_proba[desc_order]\n",
        "\n",
        "    # Get the number of positives and negatives\n",
        "    pos_count = np.sum(y_true)\n",
        "    neg_count = len(y_true) - pos_count\n",
        "\n",
        "    if pos_count == 0 or neg_count == 0:\n",
        "        return 0.5  # Handle edge case where all data points belong to one class\n",
        "\n",
        "    # Calculate true positive rate (TPR) and false positive rate (FPR)\n",
        "    tpr = np.cumsum(y_true) / pos_count\n",
        "    fpr = np.cumsum(1 - y_true) / neg_count\n",
        "\n",
        "    # Calculate the area under the curve using the trapezoidal rule\n",
        "    auc = np.trapz(tpr, fpr)\n",
        "\n",
        "    return auc\n",
        "\n",
        "# Define cross-validation function\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "\n",
        "    # Generate custom k-fold indices\n",
        "    folds = k_fold_split(X, y, n_splits)  # Call your k_fold_split function here\n",
        "\n",
        "    # Initialize list to store AUC scores\n",
        "    auc_scores = []\n",
        "\n",
        "    for fold_num, val_index in enumerate(folds, 1):\n",
        "        # Split data\n",
        "        train_index = np.hstack([folds[i] for i in range(n_splits) if i != fold_num - 1])\n",
        "        X_train, X_val = X[train_index], X[val_index]\n",
        "        y_train, y_val = y[train_index], y[val_index]\n",
        "\n",
        "        # Fit the model\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Predict probabilities\n",
        "        y_pred_proba = knn.probabilities(X_val)[:, 1]\n",
        "\n",
        "        # Compute AUC score\n",
        "        auc = custom_roc_auc_score(y_val, y_pred_proba)\n",
        "        auc_scores.append(auc)\n",
        "\n",
        "        print(f\"Fold {fold_num} AUC: {auc:.4f}\")\n",
        "\n",
        "    # Compute and print mean AUC\n",
        "    mean_auc = np.mean(auc_scores)\n",
        "    std_auc = np.std(auc_scores)\n",
        "    print(f\"\\nMean AUC: {mean_auc:.4f} (+/- {std_auc:.4f})\")\n",
        "\n",
        "    return auc_scores, mean_auc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hutvbV4_rl8x",
        "outputId": "616a2b2a-f3b3-4a1e-91e8-8c9f8ca047a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-9a8555cb4566>:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  all_data[feature].fillna(median_value, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 AUC: 0.9054\n",
            "Fold 2 AUC: 0.9152\n",
            "Fold 3 AUC: 0.9212\n",
            "Fold 4 AUC: 0.9152\n",
            "Fold 5 AUC: 0.9202\n",
            "\n",
            "Mean AUC: 0.9155 (+/- 0.0056)\n",
            "k=22, metric=euclidean: Mean AUC = 0.9155\n",
            "Fold 1 AUC: 0.9020\n",
            "Fold 2 AUC: 0.9192\n",
            "Fold 3 AUC: 0.9111\n",
            "Fold 4 AUC: 0.9026\n",
            "Fold 5 AUC: 0.9202\n",
            "\n",
            "Mean AUC: 0.9110 (+/- 0.0078)\n",
            "k=22, metric=manhattan: Mean AUC = 0.9110\n",
            "Fold 1 AUC: 0.9052\n",
            "Fold 2 AUC: 0.9192\n",
            "Fold 3 AUC: 0.9284\n",
            "Fold 4 AUC: 0.9025\n",
            "Fold 5 AUC: 0.9163\n",
            "\n",
            "Mean AUC: 0.9143 (+/- 0.0095)\n",
            "k=23, metric=euclidean: Mean AUC = 0.9143\n",
            "Fold 1 AUC: 0.9034\n",
            "Fold 2 AUC: 0.9216\n",
            "Fold 3 AUC: 0.9168\n",
            "Fold 4 AUC: 0.9136\n",
            "Fold 5 AUC: 0.9082\n",
            "\n",
            "Mean AUC: 0.9127 (+/- 0.0064)\n",
            "k=23, metric=manhattan: Mean AUC = 0.9127\n",
            "Fold 1 AUC: 0.9070\n",
            "Fold 2 AUC: 0.9198\n",
            "Fold 3 AUC: 0.9137\n",
            "Fold 4 AUC: 0.9283\n",
            "Fold 5 AUC: 0.9101\n",
            "\n",
            "Mean AUC: 0.9158 (+/- 0.0076)\n",
            "k=24, metric=euclidean: Mean AUC = 0.9158\n",
            "Fold 1 AUC: 0.9101\n",
            "Fold 2 AUC: 0.9133\n",
            "Fold 3 AUC: 0.9173\n",
            "Fold 4 AUC: 0.9122\n",
            "Fold 5 AUC: 0.9093\n",
            "\n",
            "Mean AUC: 0.9124 (+/- 0.0028)\n",
            "k=24, metric=manhattan: Mean AUC = 0.9124\n",
            "Fold 1 AUC: 0.9133\n",
            "Fold 2 AUC: 0.9166\n",
            "Fold 3 AUC: 0.9070\n",
            "Fold 4 AUC: 0.9195\n",
            "Fold 5 AUC: 0.9178\n",
            "\n",
            "Mean AUC: 0.9148 (+/- 0.0044)\n",
            "k=25, metric=euclidean: Mean AUC = 0.9148\n",
            "Fold 1 AUC: 0.9095\n",
            "Fold 2 AUC: 0.9147\n",
            "Fold 3 AUC: 0.9168\n",
            "Fold 4 AUC: 0.9086\n",
            "Fold 5 AUC: 0.9189\n",
            "\n",
            "Mean AUC: 0.9137 (+/- 0.0040)\n",
            "k=25, metric=manhattan: Mean AUC = 0.9137\n",
            "Fold 1 AUC: 0.9201\n",
            "Fold 2 AUC: 0.9079\n",
            "Fold 3 AUC: 0.9245\n",
            "Fold 4 AUC: 0.9129\n",
            "Fold 5 AUC: 0.9174\n",
            "\n",
            "Mean AUC: 0.9166 (+/- 0.0057)\n",
            "k=26, metric=euclidean: Mean AUC = 0.9166\n",
            "Fold 1 AUC: 0.9005\n",
            "Fold 2 AUC: 0.9207\n",
            "Fold 3 AUC: 0.9183\n",
            "Fold 4 AUC: 0.9013\n",
            "Fold 5 AUC: 0.9290\n",
            "\n",
            "Mean AUC: 0.9139 (+/- 0.0112)\n",
            "k=26, metric=manhattan: Mean AUC = 0.9139\n",
            "\n",
            "Best hyperparameters: k=26, metric=euclidean\n",
            "Predictions saved to submission_1.csv\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('train.csv', 'test.csv')\n",
        "\n",
        "# Ensure X, y, and X_test are numpy arrays\n",
        "X = np.array(X, dtype=float)\n",
        "y = np.array(y, dtype=int)\n",
        "X_test = np.array(X_test, dtype=float)\n",
        "\n",
        "# Hyperparameter tuning\n",
        "k_values = [22, 23, 24, 25, 26]\n",
        "distance_metrics = ['euclidean', 'manhattan']\n",
        "best_k = None\n",
        "best_metric = None\n",
        "best_auc = 0\n",
        "\n",
        "for k in k_values:\n",
        "    for metric in distance_metrics:\n",
        "        knn = KNN(k=k, distance_metric=metric)\n",
        "        auc_scores, mean_auc = cross_validate(X, y, knn)\n",
        "\n",
        "        print(f\"k={k}, metric={metric}: Mean AUC = {mean_auc:.4f}\")\n",
        "\n",
        "        if mean_auc > best_auc:\n",
        "            best_auc = mean_auc\n",
        "            best_k = k\n",
        "            best_metric = metric\n",
        "\n",
        "print(f\"\\nBest hyperparameters: k={best_k}, metric={best_metric}\")\n",
        "\n",
        "# Train on full dataset with optimal hyperparameters\n",
        "knn = KNN(k=best_k, distance_metric=best_metric)\n",
        "knn.fit(X, y)\n",
        "\n",
        "# Make predictions on test set\n",
        "test_predictions_proba = knn.probabilities(X_test)[:, 1]\n",
        "\n",
        "# Saving\n",
        "output_df = pd.DataFrame({\n",
        "    'id': pd.read_csv('test.csv')['id'],\n",
        "    'Exited': test_predictions_proba\n",
        "})\n",
        "output_path = 'submission_1.csv'\n",
        "output_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"Predictions saved to {output_path}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "cs506",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}